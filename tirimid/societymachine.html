<!DOCTYPE html>
<html>
<head>
<title>Society of a Machine</title>
<style>html {
	background-color: #ffffff;
	padding-top: 5ch;
	padding-bottom: 5ch;
}

body {
	margin-left: auto;
	margin-right: auto;
	width: 80ch;
	color: #000000;
	font-family: serif;
	font-weight: normal;
}

h1 {
	padding-top: 1ch;
	font-size: 4.5ch;
	font-weight: bold;
}

h2 {
	font-size: 3ch;
	font-weight: bold;
}

h3 {
	font-size: 2.5ch;
	font-weight: bold;
}

h4, h5, h6 {
	font-size: 2ch;
	font-weight: bold;
}

li {
	margin: 0 auto;
}

td {
	margin: 0 auto;
	padding: 1ch;
}

table {
	margin-left: 1ch;
	margin-right: 1ch;
	margin-top: 3ch;
	margin-bottom: 3ch;
	display: block;
	overflow-x: scroll;
	border-collapse: collapse;
}

tr, td {
	border: solid 1px #000000;
	border-collapse: collapse;
}

p {
	text-indent: 4ch;
	margin: 0 auto;
}

.footnote {
	padding: 1ch;
}

img {
	max-height: 100%;
	max-width: 100%;
}

a {
	color: #00779f;
}

a:hover {
	background-color: #00779f;
	color: #ffffff;
}

.long-code {
	width: 85ch;
	margin-right: 1ch;
	margin-top: 3ch;
	margin-bottom: 3ch;
	margin-left: -4ch;
	padding: 2ch;
	white-space: pre-wrap;
	tab-size: 6;
	font-family: monospace;
}

blockquote {
	text-indent: 0ch;
	margin: 0 auto;
	padding-left: 6ch;
	padding-top: 1ch;
	padding-bottom: 1ch;
}

.doc-title {
	font-size: 7ch;
}

.doc-author, .doc-date {
	color: #555555;
	font-size: 2.5ch;
}

.doc-license {
	color: #555555;
	font-size: 2.5ch;
	padding-top: 3ch;
}
</style>
<link rel="icon" type="image/x-icon" href="/res/favicon.png">
</head>
<body>
<div class="doc-title">Society of a Machine</div>
<div class="doc-author">tirimid</div>
<div class="doc-date">2025-06-05</div>
<h6>1</h6>
<p>When we talk about &quot;AI&quot; in the modern world, we have to reckon with the fact
that the vast majority of people who use and peddle it didn&apos;t even know what
that term meant until GPT came around. Talk with anybody non-technical and
you&apos;ll notice these two things - 1) they don&apos;t even know what a neural network
is, 2) they probably make active use of GPT, Stable Diffusion, etc.</p>
<h6>2</h6>
<p>This interrelationship means that most people are subject to the illusion of
intelligence that these models can mimic. It &quot;understands&quot; what you tell it,
responds in natural language, and the now-existing tooling enables it to even
perform certain tasks; this is known as an AI <i>agent</i>. Language and naming here
show their importance - why an &quot;agent&quot;? Because this term grants the model&apos;s
actions legitimacy, grants them <i>agency</i>. The illusion that supports the average
person&apos;s perception of AI as intelligent exists even at the subtlest level of
language.</p>
<h6>3</h6>
<p>Even as somebody openly skeptical of AI, we accept its premises at the
foundation. Indeed, when we even say &quot;AI&quot; in a general context, we mean GPT, we
mean image generation, agents and so forth. Of course, understanding the history
of older AI models, this is kind of absurd, as this &quot;AI&quot; constitutes but a small
fraction of things that can plausibly be considered AI. Despite this, we speak
of &quot;AI&quot; even when we&apos;re aware of this - constantly being more precise by saying
&quot;LLM&quot;, &quot;Diffusion Model&quot;, etc. begins to feel needlessly verbose. After all, we
all know what &quot;AI&quot; is.</p>
<h6>4</h6>
<p>This is not accidental, nor should it surprise us that this has happened. AI
has billions of dollars standing behind it, with billions more standing in
front. The illusion of intelligence helps to propagate the social consensus that
these are acceptable to use. Quietly allowing the modern version of &quot;AI&quot; to
enter our collective lexicon will be studied as one of the great marketing
decisions of the 21st century.</p>
<h6>5</h6>
<p>This illusion of intelligence allows the entrance of AI into domains where
intelligence, or some simulacrum thereof, is necessary. Most obviously, school
and education come to mind.</p>
<h6>6</h6>
<p>The subpar design of global educational systems has allowed their total
circumvention by this automative tool. Students are asked to write the
thousandth copy-paste-esque essay on some surface level topic requiring no real
skill beyond the ability to dutifully summarize what they&apos;ve just read on the
internet. Even in relatively forward-thinking curricula such as the IB, we see
that teaching is oriented around setting goals and meeting them. Once a goal is
formulated, it&apos;s only a matter of time before it is automated. The best learning
occurs when you are half-blindly stumbling through a novel topic and figuring
things out as you go - the obsession with quantification and goal-setting is
diametrically counterposed to this.</p>
<h6>7</h6>
<p>Once there is no &quot;figuring it out&quot; in the process of learning, there is no
longer any inherently human aspect. The joy of learning is torn asunder and the
student can no longer find any value in working. Gradually, more and more of the
student body cuts the final corner - copy-pasting and paraphrasing is no longer
the most optimal way to finish work for little effort. Instead, most assignments
can be completed through a sequence of less than a dozen clicks and the entry of
a sentence in a text field. When they do this, we can hardly be surprised.</p>
<h6>8</h6>
<p>As a student begins leaning on this perverse process, their writing ability
and general literacy atrophies and suffers. Majorities or near-majorities of
English class attendants are no longer even reading the short texts they have
been assigned; cheating in exams is easier than ever, and at an all-time high.
Students no longer engage with works because they no longer have to. This is a
self-reinforcing cycle of ignorance that will profoundly impact students long
past the point they graduate.</p>
<h6>9</h6>
<p>Neural networks also prominently reinforce this process through a secondary
process. While GPT vomits up your homework, the social media recommendation
algorithm vomits up your favorite content. The attention-span-shortening
addictive prowess of modern social media is nothing to laugh at. You automate
your only interaction with creative work to save time - for what? To make
yourself dumber and weaker in the mind over time. AI generates free time for its
user, which it then proceeds to exploit for itself, and the user is left
surveilled and servile at the whims of a machine they do not control or
understand.</p>
<h6>10</h6>
<p>At some point, some users of AI becomes so consumed by the illusion of
intelligence that it seems almost blasphemous to criticize it or its output in
its nature. Passive acceptance that &quot;it&apos;s not there yet&quot; acts as a deflection
from the critique of AI in its fundamental, irrevocable relation as a structure
that can and will make you stupid and accepting of worthless spam if that means
its owners turn a profit.</p>
<h6>11</h6>
<p>Despite it being an acceptance of AI&apos;s terms, the output should also be
criticized on its own merit. I have seldom seen text written by an AI that
didn&apos;t call out a primal aversion to it, the corporate-speak that it&apos;s so adept
at even bleeds through when you ask it not to sound like a middle manager&apos;s
LinkedIn profile. All that is non-commercial is subsumed into the language of
commercial activity, if not through vocabulary, then through syntax and style.</p>
<h6>12</h6>
<p>What we see, then, is a leveling of the playing field in the most boring
way. In a sense, the AI proponents are correct when they say that AI has
&quot;democratized&quot; writing and visual arts. Now, everybody from a disgruntled artist
to a five-year-old born with tablet in hand can generate spam with less value
than the energy taken to create it. This is the essense of capitalist democracy,
you have the freedom to democratically go fuck yourself while all the real
decisions of society (including how your self-copulation should occur) are made
right at the levers of power held by the wealthy.</p>
<h6>13</h6>
<p>Even the less artistic output of AI, code and so forth, is of miserably low
quality to a trained eye. The average programmer, however, won&apos;t see this.
Instead of trying to improve the tools so that incredibly stupid people with no
understanding of their jobs can use them, we should be asking what kind of
culture and economic structure allows these people to write the software that
powers the entire world to begin with. Looking deeper, we should ask what kind
of world allows them to be stupid (in nature, or in effect) at all. Indeed, the
degradation of key software is a trend that predates AI - this is merely the
newest wrench in an incompetent mechanic&apos;s toolbox.</p>
<h6>14</h6>
<p>No matter how we cut it, the product generated by AI is almost always of
middling quality. The main case where the average person finds actual value in
the output itself is - unsurprisingly - in the cultural domain where it doesn&apos;t
really matter. Basically, shitposts. An environment where spam is considered a
virtue and the target audience explicitly wants something bad.</p>
<h6>15</h6>
<p>AI creativity is a crude fascimile of human creativity. The only reason we
can even use the term &quot;AI art&quot; is because it approximates human art. Think again
about the nature of language and how we perceive things - if we really thought
that AI art was art, would we tack &quot;AI&quot; on as an adjective? It would seem
redundant to do so, but the fact that we do appears to reveal something
fundamental about our view of human v.s. AI creativity. Think further to
instances where authors of book series are discovered to have used AI during the
writing process; and how a minor scandal is kicked up every time it happens. We
evidently do not see AI as capable of creativity in the same way as we see
humans. And whenever we are sold AI work as if it were human, we feel cheated.</p>
<h6>16</h6>
<p>Besides the obvious examples of AI intruding upon our lives comes the fact
that web searches are becoming increasingly useless in the face of AI generating
millions of articles worth of valueless nonsense that only approaches the truth
in rare cases. Ironically, many people come to see AI as the solution - as GPT
gains secondary function as a &quot;better search engine&quot;.</p>
<h6>17</h6>
<p>The internet is so decentralized that there is no real way to clean up the
mess that AI has generated. And besides that, if every AI spam article and image
were to disappear tomorrow, the profit motives behind them would remain, and in
our capitalist world, those profit motives mean that the current state of
affairs would merely recreate itself a thousand times over.</p>
<h6>18</h6>
<p>Motives to use and abuse AI exist at almost every level of society. We have
already seen socioeducational aspects thereof, but the economic ones deserve
more attention too. These exist both at small and large scales. Large companies
push propaganda (advertising, etc.) and inculcate acceptance of the boring
dystopia we&apos;re headed towards. Every major program by every major corporation
now just has to have a lobotomite assistant, scientific progress with
questionable ethical origins is immediately coopted and an economy is built
around them before they can be meaningfully tackled. One need not look further
than the origins of image classification to understand the horrifying conditions
upon which visual generative AIs thrive. Once a large economic sector is built
around it, however, it becomes almost impossible to truly uproot an issue, no
matter how problematic it may be. The same happens at smaller scales, as
individuals create streamlined processes for generating spam to earn advertising
revenue off of. In either case, the stock value of AI and hardware companies
goes up, and the only ones who really benefit are the owners of the global
economy.</p>
<h6>19</h6>
<p>We are creating an AI sector that will eventually be too big to fail. An AI
sector that is unsustainable even in the short term. Ask yourself, how many
&quot;AI-first&quot; companies have been born and died within just the last few months?
And ask yourself, what will happen when the inexorable reality of AI&apos;s
destruction of natural resources finally catches up with us?</p>
<h6>20</h6>
<p>We are entering a world where nothing can be trusted that you haven&apos;t seen
in person, where the world&apos;s most brilliant engineers are tasked with making you
addicted to something that makes you dumber, where school and education have
already been turned upside down and students have no reason to learn but their
own - increasingly rare - wish to do so, where creativity is increasingly
automated and we will eventually get used to that fact; losing respect for the
works of art that made us human to begin with. We are entering the world of AI.</p>
<h6>21</h6>
<p>Two main things are possible - we will either eliminate the profit motives
foundational to society which make perversions of technology possible, or we
will forever mark the 21st century as the turning point in the global
apocalypse. The environmental concerns of technology such as AI are simply too
grave to ignore.</p>
<h6>22</h6>
<p>AI is not a morally neutral tool. When you use it, you train it. When you
train it, you help to improve the very thing that wants to destroy your critical
thinking and ability to live independent of technology. Do not deceive yourself
and say it&apos;s &quot;just another tool&quot;. It is certainly a tool, but it is most
definitely not &quot;just another&quot; one.</p>
<h6>23</h6>
<p>When using or engaging with AI, stay intensely critical of anything and
everything it outputs. The fact that something was generated by AI should be a
cause of skepticism of its validity, the same way you would be skeptical of
claims or output disseminated by a self-interested political organization. This
is if you cannot, or do not want to, avoid engaging with AI outright.</p>
<h6>24</h6>
<p>AI would not turn into what it has in a better world culture. The only
reason it has managed to reach the destructive peaks that it has, cannibalizing
all the internet&apos;s information and regurgitating it in a lawless amalgam, is due
to our economic structure, and thus the culture that arises in our societies.
The obsession with &quot;efficiency&quot;, the disregard for long-term consequence, the
constant chase for profits, the need of the economic owning class to own and
control the lower classes through any available means, are all reasons things
have gotten as bad as they have.</p>
<h6>25</h6>
<p>AI does have some potential to be a worthwhile tool in some limited use
cases. People have generally started to realize that the scare about self-aware
AI coming about and subjugating the human race was mostly that - a scare. We
will not get trapped in some terrifying dystopia; we already have much worse, a
boring dystopia. A boring and profoundly mediocre dystopia where all that is
solid melts to commercial sludge. As humans, we have no hope of stopping this
without deep systemic change of many cultural-economic social structures.
Without that, we might as well be making no progress at all. Do not stay blindly
accepting of reality, things are not alright as they are. And in its current
form, AI will become the latest tool of control which strips you of your life,
and your life of meaning. AI agents replace your agency despite protest. AI
creativity encroaches on human creativity despite our disdain for it. AI writing
pushes valuable writing out of visibility. AI military tools choose who will die
and who will live. AI drones vaporize innocent people.</p>
<h6>26</h6>
<p>Do not accept the new status quo. Do not let yourself be consumed in the
various illusions of AI. AI is not morally neutral.
</p>
<div class="doc-license"><p xmlns:cc="http://creativecommons.org/ns#" >This work by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://tirimid.net">tirimid</a> is licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p></div></body>
</html>
